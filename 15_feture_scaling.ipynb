{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling \n",
    "# all the distance based algorithem have a one issue , it reflact the performatce\n",
    "### studied_hour , IQ , problem solved , package , state (happy/unhappy)\n",
    "> - now we need focuse on package , whenever we find the distance .the algo is baies of package ,becouse of this we loss the importance of other features (f1,f2,f3)\n",
    "> - for find the right value we need to scale the table (all values are in same level) , that's called <mark> Feature Scaling <mark>\n",
    "\n",
    "for scale the data we use veriouse processes like \n",
    "- **Mean Normalization**\n",
    "- **Standarization**\n",
    "- **MIN-MAX-SCALING**\n",
    "- Robust scaling\n",
    "- Max abs scaling\n",
    "- power transfer\n",
    "- unit vector\n",
    "- and more .......\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     3    100     10 500000]\n",
      " [     4     20     20 400000]\n",
      " [     5     40     15 750000]\n",
      " [     4    140      5 850000]\n",
      " [     5     40     15 700000]\n",
      " [     6     10     15 650000]\n",
      " [     2     20     15 450000]]\n"
     ]
    }
   ],
   "source": [
    "import numpy \n",
    "study_hour =[3, 4, 5, 4, 5, 6, 2]\n",
    "IQ = [100, 20, 40, 140, 40, 10, 20]\n",
    "gfg_quetion_solved = [10,20,15,5,15,15,15]\n",
    "package = [500000, 400000, 750000, 850000, 700000, 650000, 450000]\n",
    "\n",
    "table = numpy.matrix((study_hour,IQ,gfg_quetion_solved,package)).T\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.14285714e+00 5.28571429e+01 1.35714286e+01 6.14285714e+05]]\n",
      "[[     6    140     20 850000]]\n",
      "[[     2     10      5 400000]]\n",
      "**************************************************\n",
      "scaled table now all the cloumn are equal level\n",
      "[[-0.28571429  0.36263736 -0.23809524 -0.25396825]\n",
      " [-0.03571429 -0.25274725  0.42857143 -0.47619048]\n",
      " [ 0.21428571 -0.0989011   0.0952381   0.3015873 ]\n",
      " [-0.03571429  0.67032967 -0.57142857  0.52380952]\n",
      " [ 0.21428571 -0.0989011   0.0952381   0.19047619]\n",
      " [ 0.46428571 -0.32967033  0.0952381   0.07936508]\n",
      " [-0.53571429 -0.25274725  0.0952381  -0.36507937]]\n"
     ]
    }
   ],
   "source": [
    "# Mean Normalization\n",
    "# x-mean(set(x))/max(set(x))-min(set(x))\n",
    "\n",
    "mean_arr = numpy.mean(table , axis=0)\n",
    "max_arr = numpy.max(table,axis=0)\n",
    "min_arr = numpy.min(table,axis=0)\n",
    "print(mean_arr)\n",
    "print(max_arr)\n",
    "print(min_arr)\n",
    "\n",
    "def get_mean_normalization(a):\n",
    "    return [(a[x]-mean_arr[x])/(max_arr[x]-min_arr[x]) for x in range(len(a))]\n",
    "# mat=numpy.apply_along_axis(lambda a:[(a[x]-mean_arr[x])/(max_arr[x]-min_arr[x]) for x in range(len(a))],1,table)\n",
    "mat = numpy.apply_along_axis(get_mean_normalization,1,table)\n",
    "scaled_table=numpy.matrix(mat)\n",
    "print('*'*50)\n",
    "print('scaled table now all the cloumn are equal level')\n",
    "print(scaled_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.14285714e+00 5.28571429e+01 1.35714286e+01 6.14285714e+05]]\n",
      "[[1.24539970e+00 4.49489506e+01 4.40315286e+00 1.55182578e+05]]\n",
      "**************************************************\n",
      "scaled table now all the cloumn are equal level\n",
      "[[-0.91766294  1.04880885 -0.81110711 -0.73645969]\n",
      " [-0.11470787 -0.73098799  1.45999279 -1.38086193]\n",
      " [ 0.6882472  -0.28603878  0.32444284  0.87454589]\n",
      " [-0.11470787  1.93870726 -1.94665705  1.51894812]\n",
      " [ 0.6882472  -0.28603878  0.32444284  0.55234477]\n",
      " [ 1.49120227 -0.95346259  0.32444284  0.23014365]\n",
      " [-1.720618   -0.73098799  0.32444284 -1.05866081]]\n"
     ]
    }
   ],
   "source": [
    "# Standarization\n",
    "import statistics\n",
    "# x-mean(set(x))/            (math.sqrt((x-mean(set(x)))**2/n)) # std deviation\n",
    "mean_arr = numpy.mean(table , axis=0)\n",
    "print(mean_arr)\n",
    "\n",
    "# mean_=numpy.mean(table , axis=0)\n",
    "# sub = numpy.subtract(table,mean_)\n",
    "# square_=numpy.square(sub)\n",
    "# variance = numpy.mean(square_,axis=0)\n",
    "# std_arr = numpy.sqrt(variance)\n",
    "std_arr=numpy.std(table,axis=0)\n",
    "print(std_arr)\n",
    "\n",
    "\n",
    "def get_standarization(a):\n",
    "        return [(a[i]-mean_arr[i])/std_arr[i] for i in range(len(a))]\n",
    "\n",
    "mat = numpy.apply_along_axis(get_standarization,1,table)\n",
    "scaled_table=numpy.matrix(mat)\n",
    "print('*'*50)\n",
    "print('scaled table now all the cloumn are equal level')\n",
    "print(scaled_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     6    140     20 850000]]\n",
      "[[     2     10      5 400000]]\n",
      "**************************************************\n",
      "scaled table now all the cloumn are equal level\n",
      "[[0.25       0.69230769 0.33333333 0.22222222]\n",
      " [0.5        0.07692308 1.         0.        ]\n",
      " [0.75       0.23076923 0.66666667 0.77777778]\n",
      " [0.5        1.         0.         1.        ]\n",
      " [0.75       0.23076923 0.66666667 0.66666667]\n",
      " [1.         0.         0.66666667 0.55555556]\n",
      " [0.         0.07692308 0.66666667 0.11111111]]\n"
     ]
    }
   ],
   "source": [
    "# MIN-MAX-SCALING\n",
    "# x-min(set(x))/max(set(x))-min(set(x))\n",
    "\n",
    "max_arr = numpy.max(table,axis=0)\n",
    "min_arr = numpy.min(table,axis=0)\n",
    "print(max_arr)\n",
    "print(min_arr)\n",
    "\n",
    "def get_min_max_scaling(a):\n",
    "    return [(a[x]-min_arr[x])/(max_arr[x]-min_arr[x]) for x in range(len(a))]\n",
    "mat = numpy.apply_along_axis(get_min_max_scaling,1,table)\n",
    "scaled_table=numpy.matrix(mat)\n",
    "print('*'*50)\n",
    "print('scaled table now all the cloumn are equal level')\n",
    "print(scaled_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Assignment\n",
    "- Robust scaling\n",
    "- Max abs scaling\n",
    "- power transfer\n",
    "- unit vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
