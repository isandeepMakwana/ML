{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's create a KNN Algo with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install sklearn\n",
    "\n",
    "import sklearn.datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load demo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load demo data from sklearn\n",
    "iris = sklearn.datasets.load_iris()\n",
    "print(iris)\n",
    "# print(type(iris))\n",
    "# print(iris.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.target)\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = iris.data\n",
    "target_names = iris.target_names\n",
    "target  = iris.target\n",
    "print(data[0])\n",
    "print(target[0])\n",
    "print(target_names[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's create KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisDataset = sklearn.datasets.load_iris()\n",
    "featuresData = irisDataset.data[:,:2]\n",
    "\n",
    "targetData = irisDataset.target\n",
    "print(featuresData)\n",
    "# print(type(featuresData))\n",
    "print(targetData)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_test_split()\n",
    "- split the data to train and test data\n",
    "<p>feature data ko split karte hai</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featuresTrainingData , featuresTestData = sklearn.model_selection.train_test_split(featuresData,test_size=0.25) # test_size means % of testdata if test_size = 0.25 then featrueTestData is 25%\n",
    "# print(\"percentage of featureTrainingData : \",len(featuresTrainingData)/len(featuresData))\n",
    "# print(\"percentage of featrueTestData : \",len(featuresTestData)/len(featuresData))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>feature and traget data ko split karte hai</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresTrainingData , featuresTestData , targetTrainingData, targetTestData  = sklearn.model_selection.train_test_split(featuresData, targetData , test_size=0.25)\n",
    "print(\"Feature - Training Data\")\n",
    "print(featuresTrainingData)\n",
    "print(\"Feature - Test Data\")\n",
    "print(featuresTestData)\n",
    "print(\"Target - Training Data\")\n",
    "print(targetTrainingData)\n",
    "print(\"Target - Test Data\")\n",
    "print(targetTestData)\n",
    "print(len(targetTrainingData) , len(targetTestData))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scale the data \n",
    "scaler = sklearn.preprocessing.StandardScaler().fit(featuresTrainingData)\n",
    "print(type(scaler))\n",
    "print('Mean',scaler.mean_)\n",
    "print(\"Variance : \",scaler.scale_)\n",
    "featuresTrainingData = scaler.transform(featuresTrainingData)\n",
    "featuresTestData = scaler.transform(featuresTestData)\n",
    "print(\"scaled Trining DATA : \")\n",
    "print(featuresTrainingData)\n",
    "print(\"scaled test DATA :\")\n",
    "print(featuresTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "# print(knn , type(knn))\n",
    "print(len(targetTrainingData))\n",
    "knn.fit(featuresTrainingData,targetTrainingData)\n",
    "result = knn.predict(featuresTestData)\n",
    "print(\"The results\")\n",
    "print(result)\n",
    "print(\"the actuals\")\n",
    "print(targetTestData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "130826a50b4030fecff09c60f733bc90a93922839765dc4abeb8c6376ff802e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
