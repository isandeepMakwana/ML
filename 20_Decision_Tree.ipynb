{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deesion Tree:\n",
    "\n",
    "## step 1: splitting data using information theory \n",
    "> that means watch the unfamiler data and create some rules . but remember that unfamiler_data have target \"using probability theory \"\n",
    "> - we have multiple feature \n",
    "> - f1 | f2 | f3 | f4 |f5\n",
    "> so split with the basic of information gain 'which feature have highest information gain we split with that feature .'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whenever we talk about information gain , we need to calculate **Entropy**\n",
    "#### **Shanon Entropy**  (measure / amount of disorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H(x1) = - nEi=1  P(xi).log2P(xi)\n",
    "\n",
    "# P(xi) = number of times the class has Occurs in dataset/number of records in dataset\n",
    "\n",
    "# f1 | f2 | f3 | f4 | target\n",
    "# -    -     -   -     A\n",
    "# -    -     -   -     A\n",
    "# -    -     -   -     B\n",
    "# -    -     -   -     B\n",
    "# -    -     -   -     B\n",
    "# -    -     -   -     C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4591479170272448\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "s_en = float(0) # shanon entropy\n",
    "p=float(2)/6   # 6 is to no of rows\n",
    "s_en = s_en - (p*math.log(p,2))\n",
    "p=float(3)/6 \n",
    "s_en = s_en - (p*math.log(p,2))\n",
    "p=float(1)/6 \n",
    "s_en = s_en - (p*math.log(p,2))\n",
    "print(s_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "# decreses the classes \n",
    "import math\n",
    "s_en = float(0) # shanon entropy\n",
    "p=float(2)/5   # 5 is to no of rows\n",
    "s_en = s_en - (p*math.log(p,2))\n",
    "p=float(3)/5\n",
    "s_en = s_en - (p*math.log(p,2))\n",
    "\n",
    "print(s_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9056390622295662\n"
     ]
    }
   ],
   "source": [
    "# increases the classes \n",
    "import math\n",
    "s_en = float(0) # shanon entropy\n",
    "p=float(2)/8   # 8 is to no of rows\n",
    "s_en = s_en - (p*math.log(p,2))\n",
    "p=float(3)/8\n",
    "s_en = s_en - (p*math.log(p,2))\n",
    "p=float(1)/8 \n",
    "s_en = s_en - (p*math.log(p,2))\n",
    "p=float(2)/8 \n",
    "s_en = s_en - (p*math.log(p,2))\n",
    "print(s_en)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - When we incresing no of classes Entropy will be increses.\n",
    "# - When we decresing no of classes Entropy will be decreses.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
